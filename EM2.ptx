//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: CL-25769353
// Cuda compilation tools, release 10.1, V10.1.105
// Based on LLVM 3.4svn
//

.version 6.4
.target sm_30
.address_size 64

	// .globl	_Z24processMandelbrotElementPdS_S_S_S_S_S_S_S_Piidddddd
.func  (.param .b64 func_retval0) __internal_trig_reduction_slowpathd
(
	.param .b64 __internal_trig_reduction_slowpathd_param_0,
	.param .b64 __internal_trig_reduction_slowpathd_param_1
)
;
.const .align 8 .b8 __cudart_i2opi_d[144] = {8, 93, 141, 31, 177, 95, 251, 107, 234, 146, 82, 138, 247, 57, 7, 61, 123, 241, 229, 235, 199, 186, 39, 117, 45, 234, 95, 158, 102, 63, 70, 79, 183, 9, 203, 39, 207, 126, 54, 109, 31, 109, 10, 90, 139, 17, 47, 239, 15, 152, 5, 222, 255, 151, 248, 31, 59, 40, 249, 189, 139, 95, 132, 156, 244, 57, 83, 131, 57, 214, 145, 57, 65, 126, 95, 180, 38, 112, 156, 233, 132, 68, 187, 46, 245, 53, 130, 232, 62, 167, 41, 177, 28, 235, 29, 254, 28, 146, 209, 9, 234, 46, 73, 6, 224, 210, 77, 66, 58, 110, 36, 183, 97, 197, 187, 222, 171, 99, 81, 254, 65, 144, 67, 60, 153, 149, 98, 219, 192, 221, 52, 245, 209, 87, 39, 252, 41, 21, 68, 78, 110, 131, 249, 162};
.const .align 8 .b8 __cudart_sin_cos_coeffs[128] = {186, 94, 120, 249, 101, 219, 229, 61, 70, 210, 176, 44, 241, 229, 90, 190, 146, 227, 172, 105, 227, 29, 199, 62, 161, 98, 219, 25, 160, 1, 42, 191, 24, 8, 17, 17, 17, 17, 129, 63, 84, 85, 85, 85, 85, 85, 197, 191, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 100, 129, 253, 32, 131, 255, 168, 189, 40, 133, 239, 193, 167, 238, 33, 62, 217, 230, 6, 142, 79, 126, 146, 190, 233, 188, 221, 25, 160, 1, 250, 62, 71, 93, 193, 22, 108, 193, 86, 191, 81, 85, 85, 85, 85, 85, 165, 63, 0, 0, 0, 0, 0, 0, 224, 191, 0, 0, 0, 0, 0, 0, 240, 63};

.visible .entry _Z24processMandelbrotElementPdS_S_S_S_S_S_S_S_Piidddddd(
	.param .u64 _Z24processMandelbrotElementPdS_S_S_S_S_S_S_S_Piidddddd_param_0,
	.param .u64 _Z24processMandelbrotElementPdS_S_S_S_S_S_S_S_Piidddddd_param_1,
	.param .u64 _Z24processMandelbrotElementPdS_S_S_S_S_S_S_S_Piidddddd_param_2,
	.param .u64 _Z24processMandelbrotElementPdS_S_S_S_S_S_S_S_Piidddddd_param_3,
	.param .u64 _Z24processMandelbrotElementPdS_S_S_S_S_S_S_S_Piidddddd_param_4,
	.param .u64 _Z24processMandelbrotElementPdS_S_S_S_S_S_S_S_Piidddddd_param_5,
	.param .u64 _Z24processMandelbrotElementPdS_S_S_S_S_S_S_S_Piidddddd_param_6,
	.param .u64 _Z24processMandelbrotElementPdS_S_S_S_S_S_S_S_Piidddddd_param_7,
	.param .u64 _Z24processMandelbrotElementPdS_S_S_S_S_S_S_S_Piidddddd_param_8,
	.param .u64 _Z24processMandelbrotElementPdS_S_S_S_S_S_S_S_Piidddddd_param_9,
	.param .u32 _Z24processMandelbrotElementPdS_S_S_S_S_S_S_S_Piidddddd_param_10,
	.param .f64 _Z24processMandelbrotElementPdS_S_S_S_S_S_S_S_Piidddddd_param_11,
	.param .f64 _Z24processMandelbrotElementPdS_S_S_S_S_S_S_S_Piidddddd_param_12,
	.param .f64 _Z24processMandelbrotElementPdS_S_S_S_S_S_S_S_Piidddddd_param_13,
	.param .f64 _Z24processMandelbrotElementPdS_S_S_S_S_S_S_S_Piidddddd_param_14,
	.param .f64 _Z24processMandelbrotElementPdS_S_S_S_S_S_S_S_Piidddddd_param_15,
	.param .f64 _Z24processMandelbrotElementPdS_S_S_S_S_S_S_S_Piidddddd_param_16
)
{
	.local .align 4 .b8 	__local_depot0[4];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<73>;
	.reg .b32 	%r<349>;
	.reg .f64 	%fd<617>;
	.reg .b64 	%rd<200>;


	mov.u64 	%SPL, __local_depot0;
	cvta.local.u64 	%SP, %SPL;
	ld.param.u64 	%rd9, [_Z24processMandelbrotElementPdS_S_S_S_S_S_S_S_Piidddddd_param_0];
	ld.param.u64 	%rd10, [_Z24processMandelbrotElementPdS_S_S_S_S_S_S_S_Piidddddd_param_1];
	ld.param.u64 	%rd11, [_Z24processMandelbrotElementPdS_S_S_S_S_S_S_S_Piidddddd_param_2];
	ld.param.u64 	%rd12, [_Z24processMandelbrotElementPdS_S_S_S_S_S_S_S_Piidddddd_param_3];
	ld.param.u64 	%rd13, [_Z24processMandelbrotElementPdS_S_S_S_S_S_S_S_Piidddddd_param_4];
	ld.param.u64 	%rd14, [_Z24processMandelbrotElementPdS_S_S_S_S_S_S_S_Piidddddd_param_5];
	ld.param.u64 	%rd15, [_Z24processMandelbrotElementPdS_S_S_S_S_S_S_S_Piidddddd_param_6];
	ld.param.u64 	%rd16, [_Z24processMandelbrotElementPdS_S_S_S_S_S_S_S_Piidddddd_param_7];
	ld.param.u64 	%rd18, [_Z24processMandelbrotElementPdS_S_S_S_S_S_S_S_Piidddddd_param_9];
	ld.param.u32 	%r45, [_Z24processMandelbrotElementPdS_S_S_S_S_S_S_S_Piidddddd_param_10];
	ld.param.f64 	%fd183, [_Z24processMandelbrotElementPdS_S_S_S_S_S_S_S_Piidddddd_param_11];
	ld.param.f64 	%fd185, [_Z24processMandelbrotElementPdS_S_S_S_S_S_S_S_Piidddddd_param_13];
	ld.param.f64 	%fd186, [_Z24processMandelbrotElementPdS_S_S_S_S_S_S_S_Piidddddd_param_16];
	mov.u32 	%r46, %nctaid.x;
	mov.u32 	%r47, %ctaid.y;
	mov.u32 	%r48, %ctaid.x;
	mad.lo.s32 	%r49, %r46, %r47, %r48;
	mov.u32 	%r50, %ntid.y;
	mov.u32 	%r51, %tid.y;
	mad.lo.s32 	%r52, %r50, %r49, %r51;
	mov.u32 	%r53, %ntid.x;
	mov.u32 	%r54, %tid.x;
	mad.lo.s32 	%r55, %r52, %r53, %r54;
	setp.ge.s32	%p1, %r55, %r45;
	@%p1 bra 	BB0_125;

	cvta.to.global.u64 	%rd19, %rd18;
	mul.wide.s32 	%rd20, %r55, 4;
	add.s64 	%rd21, %rd19, %rd20;
	ld.global.u32 	%r66, [%rd21];
	setp.eq.s32	%p2, %r66, 1;
	@%p2 bra 	BB0_125;

	cvta.to.global.u64 	%rd22, %rd9;
	mul.wide.s32 	%rd23, %r55, 8;
	add.s64 	%rd24, %rd22, %rd23;
	cvta.to.global.u64 	%rd25, %rd12;
	add.s64 	%rd26, %rd25, %rd23;
	ld.global.f64 	%fd187, [%rd26];
	mul.f64 	%fd188, %fd187, 0d3FE0000000000000;
	ld.global.f64 	%fd189, [%rd24];
	fma.rn.f64 	%fd190, %fd188, %fd186, %fd189;
	st.global.f64 	[%rd24], %fd190;
	cvta.to.global.u64 	%rd27, %rd10;
	add.s64 	%rd28, %rd27, %rd23;
	cvta.to.global.u64 	%rd29, %rd13;
	add.s64 	%rd30, %rd29, %rd23;
	ld.global.f64 	%fd191, [%rd30];
	mul.f64 	%fd192, %fd191, 0d3FE0000000000000;
	ld.global.f64 	%fd193, [%rd28];
	fma.rn.f64 	%fd194, %fd192, %fd186, %fd193;
	st.global.f64 	[%rd28], %fd194;
	cvta.to.global.u64 	%rd31, %rd11;
	add.s64 	%rd32, %rd31, %rd23;
	cvta.to.global.u64 	%rd33, %rd14;
	add.s64 	%rd34, %rd33, %rd23;
	ld.global.f64 	%fd195, [%rd34];
	mul.f64 	%fd196, %fd195, 0d3FE0000000000000;
	ld.global.f64 	%fd197, [%rd32];
	fma.rn.f64 	%fd198, %fd196, %fd186, %fd197;
	st.global.f64 	[%rd32], %fd198;
	ld.global.f64 	%fd199, [%rd24];
	ld.global.f64 	%fd200, [%rd28];
	mul.f64 	%fd201, %fd200, %fd200;
	fma.rn.f64 	%fd202, %fd199, %fd199, %fd201;
	sqrt.rn.f64 	%fd203, %fd202;
	cvta.to.global.u64 	%rd35, %rd15;
	add.s64 	%rd36, %rd35, %rd23;
	st.global.f64 	[%rd36], %fd203;
	ld.global.f64 	%fd204, [%rd24];
	ld.global.f64 	%fd205, [%rd28];
	div.rn.f64 	%fd1, %fd205, %fd204;
	abs.f64 	%fd2, %fd1;
	setp.leu.f64	%p3, %fd2, 0d3FF0000000000000;
	mov.f64 	%fd562, %fd2;
	@%p3 bra 	BB0_4;

	rcp.approx.ftz.f64 	%fd206, %fd2;
	neg.f64 	%fd207, %fd2;
	mov.f64 	%fd208, 0d3FF0000000000000;
	fma.rn.f64 	%fd209, %fd207, %fd206, %fd208;
	fma.rn.f64 	%fd210, %fd209, %fd209, %fd209;
	fma.rn.f64 	%fd211, %fd210, %fd206, %fd206;
	setp.eq.f64	%p4, %fd2, 0d7FF0000000000000;
	selp.f64	%fd562, 0d0000000000000000, %fd211, %p4;

BB0_4:
	mul.f64 	%fd212, %fd562, %fd562;
	mov.f64 	%fd213, 0d3F2D3B63DBB65B49;
	mov.f64 	%fd214, 0dBEF53E1D2A25FF7E;
	fma.rn.f64 	%fd215, %fd214, %fd212, %fd213;
	mov.f64 	%fd216, 0dBF5312788DDE082E;
	fma.rn.f64 	%fd217, %fd215, %fd212, %fd216;
	mov.f64 	%fd218, 0d3F6F9690C8249315;
	fma.rn.f64 	%fd219, %fd217, %fd212, %fd218;
	mov.f64 	%fd220, 0dBF82CF5AABC7CF0D;
	fma.rn.f64 	%fd221, %fd219, %fd212, %fd220;
	mov.f64 	%fd222, 0d3F9162B0B2A3BFDE;
	fma.rn.f64 	%fd223, %fd221, %fd212, %fd222;
	mov.f64 	%fd224, 0dBF9A7256FEB6FC6B;
	fma.rn.f64 	%fd225, %fd223, %fd212, %fd224;
	mov.f64 	%fd226, 0d3FA171560CE4A489;
	fma.rn.f64 	%fd227, %fd225, %fd212, %fd226;
	mov.f64 	%fd228, 0dBFA4F44D841450E4;
	fma.rn.f64 	%fd229, %fd227, %fd212, %fd228;
	mov.f64 	%fd230, 0d3FA7EE3D3F36BB95;
	fma.rn.f64 	%fd231, %fd229, %fd212, %fd230;
	mov.f64 	%fd232, 0dBFAAD32AE04A9FD1;
	fma.rn.f64 	%fd233, %fd231, %fd212, %fd232;
	mov.f64 	%fd234, 0d3FAE17813D66954F;
	fma.rn.f64 	%fd235, %fd233, %fd212, %fd234;
	mov.f64 	%fd236, 0dBFB11089CA9A5BCD;
	fma.rn.f64 	%fd237, %fd235, %fd212, %fd236;
	mov.f64 	%fd238, 0d3FB3B12B2DB51738;
	fma.rn.f64 	%fd239, %fd237, %fd212, %fd238;
	mov.f64 	%fd240, 0dBFB745D022F8DC5C;
	fma.rn.f64 	%fd241, %fd239, %fd212, %fd240;
	mov.f64 	%fd242, 0d3FBC71C709DFE927;
	fma.rn.f64 	%fd243, %fd241, %fd212, %fd242;
	mov.f64 	%fd244, 0dBFC2492491FA1744;
	fma.rn.f64 	%fd245, %fd243, %fd212, %fd244;
	mov.f64 	%fd246, 0d3FC99999999840D2;
	fma.rn.f64 	%fd247, %fd245, %fd212, %fd246;
	mov.f64 	%fd248, 0dBFD555555555544C;
	fma.rn.f64 	%fd249, %fd247, %fd212, %fd248;
	mul.f64 	%fd250, %fd212, %fd249;
	fma.rn.f64 	%fd251, %fd250, %fd562, %fd562;
	mov.f64 	%fd252, 0d3FF921FB54442D18;
	sub.f64 	%fd253, %fd252, %fd251;
	setp.gt.f64	%p5, %fd2, 0d3FF0000000000000;
	selp.f64	%fd254, %fd253, %fd251, %p5;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r77, %temp}, %fd254;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r78}, %fd254;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r79}, %fd1;
	}
	and.b32  	%r80, %r79, -2147483648;
	or.b32  	%r81, %r78, %r80;
	mov.b64 	%fd599, {%r77, %r81};
	cvta.to.global.u64 	%rd37, %rd16;
	add.s64 	%rd1, %rd37, %rd23;
	st.global.f64 	[%rd1], %fd599;
	ld.global.f64 	%fd255, [%rd36];
	setp.leu.f64	%p6, %fd255, %fd183;
	@%p6 bra 	BB0_6;

	mov.u32 	%r102, 1;
	st.global.u32 	[%rd21], %r102;
	ld.global.f64 	%fd599, [%rd1];

BB0_6:
	setp.geu.f64	%p7, %fd599, 0d0000000000000000;
	@%p7 bra 	BB0_45;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r103}, %fd185;
	}
	and.b32  	%r1, %r103, 2147483647;

BB0_8:
	add.f64 	%fd256, %fd599, %fd185;
	st.global.f64 	[%rd1], %fd256;
	ld.global.f64 	%fd9, [%rd26];
	setp.ne.s32	%p8, %r1, 2146435072;
	mov.f64 	%fd565, %fd185;
	@%p8 bra 	BB0_11;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r114, %temp}, %fd185;
	}
	setp.ne.s32	%p9, %r114, 0;
	mov.f64 	%fd565, %fd185;
	@%p9 bra 	BB0_11;

	mov.f64 	%fd257, 0d0000000000000000;
	mul.rn.f64 	%fd565, %fd185, %fd257;

BB0_11:
	mul.f64 	%fd258, %fd565, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64	%r337, %fd258;
	add.u64 	%rd49, %SP, 0;
	add.u64 	%rd50, %SPL, 0;
	st.local.u32 	[%rd50], %r337;
	cvt.rn.f64.s32	%fd259, %r337;
	neg.f64 	%fd260, %fd259;
	fma.rn.f64 	%fd262, %fd260, %fd252, %fd565;
	mov.f64 	%fd263, 0d3C91A62633145C00;
	fma.rn.f64 	%fd264, %fd260, %fd263, %fd262;
	mov.f64 	%fd265, 0d397B839A252049C0;
	fma.rn.f64 	%fd566, %fd260, %fd265, %fd264;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r115}, %fd565;
	}
	and.b32  	%r116, %r115, 2145386496;
	setp.lt.u32	%p10, %r116, 1105199104;
	@%p10 bra 	BB0_13;

	// Callseq Start 0
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd565;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd49;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd566, [retval0+0];
	
	//{
	}// Callseq End 0
	ld.local.u32 	%r337, [%rd50];

BB0_13:
	add.s32 	%r5, %r337, 1;
	and.b32  	%r117, %r5, 1;
	shl.b32 	%r118, %r117, 3;
	setp.eq.s32	%p11, %r117, 0;
	selp.f64	%fd266, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p11;
	add.s32 	%r119, %r118, 1;
	mul.wide.s32 	%rd53, %r119, 8;
	mov.u64 	%rd54, __cudart_sin_cos_coeffs;
	add.s64 	%rd55, %rd54, %rd53;
	ld.const.f64 	%fd267, [%rd55];
	mul.rn.f64 	%fd15, %fd566, %fd566;
	fma.rn.f64 	%fd268, %fd266, %fd15, %fd267;
	ld.const.f64 	%fd269, [%rd55+8];
	fma.rn.f64 	%fd270, %fd268, %fd15, %fd269;
	ld.const.f64 	%fd271, [%rd55+16];
	fma.rn.f64 	%fd272, %fd270, %fd15, %fd271;
	ld.const.f64 	%fd273, [%rd55+24];
	fma.rn.f64 	%fd274, %fd272, %fd15, %fd273;
	ld.const.f64 	%fd275, [%rd55+32];
	fma.rn.f64 	%fd276, %fd274, %fd15, %fd275;
	ld.const.f64 	%fd277, [%rd55+40];
	fma.rn.f64 	%fd16, %fd276, %fd15, %fd277;
	fma.rn.f64 	%fd567, %fd16, %fd566, %fd566;
	@%p11 bra 	BB0_15;

	mov.f64 	%fd278, 0d3FF0000000000000;
	fma.rn.f64 	%fd567, %fd16, %fd15, %fd278;

BB0_15:
	and.b32  	%r120, %r5, 2;
	setp.eq.s32	%p12, %r120, 0;
	@%p12 bra 	BB0_17;

	mov.f64 	%fd279, 0d0000000000000000;
	mov.f64 	%fd280, 0dBFF0000000000000;
	fma.rn.f64 	%fd567, %fd567, %fd280, %fd279;

BB0_17:
	mul.f64 	%fd22, %fd9, %fd567;
	ld.global.f64 	%fd23, [%rd30];
	mov.f64 	%fd569, %fd185;
	@%p8 bra 	BB0_20;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r131, %temp}, %fd185;
	}
	setp.ne.s32	%p14, %r131, 0;
	mov.f64 	%fd569, %fd185;
	@%p14 bra 	BB0_20;

	mov.f64 	%fd281, 0d0000000000000000;
	mul.rn.f64 	%fd569, %fd185, %fd281;

BB0_20:
	mul.f64 	%fd282, %fd569, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64	%r338, %fd282;
	st.local.u32 	[%rd50], %r338;
	cvt.rn.f64.s32	%fd283, %r338;
	neg.f64 	%fd284, %fd283;
	fma.rn.f64 	%fd286, %fd284, %fd252, %fd569;
	fma.rn.f64 	%fd288, %fd284, %fd263, %fd286;
	fma.rn.f64 	%fd570, %fd284, %fd265, %fd288;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r132}, %fd569;
	}
	and.b32  	%r133, %r132, 2145386496;
	setp.lt.u32	%p15, %r133, 1105199104;
	@%p15 bra 	BB0_22;

	// Callseq Start 1
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd569;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd49;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd570, [retval0+0];
	
	//{
	}// Callseq End 1
	ld.local.u32 	%r338, [%rd50];

BB0_22:
	and.b32  	%r134, %r338, 1;
	shl.b32 	%r135, %r134, 3;
	setp.eq.s32	%p16, %r134, 0;
	selp.f64	%fd290, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p16;
	add.s32 	%r136, %r135, 1;
	mul.wide.s32 	%rd63, %r136, 8;
	add.s64 	%rd65, %rd54, %rd63;
	ld.const.f64 	%fd291, [%rd65];
	mul.rn.f64 	%fd29, %fd570, %fd570;
	fma.rn.f64 	%fd292, %fd290, %fd29, %fd291;
	ld.const.f64 	%fd293, [%rd65+8];
	fma.rn.f64 	%fd294, %fd292, %fd29, %fd293;
	ld.const.f64 	%fd295, [%rd65+16];
	fma.rn.f64 	%fd296, %fd294, %fd29, %fd295;
	ld.const.f64 	%fd297, [%rd65+24];
	fma.rn.f64 	%fd298, %fd296, %fd29, %fd297;
	ld.const.f64 	%fd299, [%rd65+32];
	fma.rn.f64 	%fd300, %fd298, %fd29, %fd299;
	ld.const.f64 	%fd301, [%rd65+40];
	fma.rn.f64 	%fd30, %fd300, %fd29, %fd301;
	fma.rn.f64 	%fd571, %fd30, %fd570, %fd570;
	@%p16 bra 	BB0_24;

	mov.f64 	%fd302, 0d3FF0000000000000;
	fma.rn.f64 	%fd571, %fd30, %fd29, %fd302;

BB0_24:
	and.b32  	%r137, %r338, 2;
	setp.eq.s32	%p17, %r137, 0;
	@%p17 bra 	BB0_26;

	mov.f64 	%fd303, 0d0000000000000000;
	mov.f64 	%fd304, 0dBFF0000000000000;
	fma.rn.f64 	%fd571, %fd571, %fd304, %fd303;

BB0_26:
	mul.f64 	%fd305, %fd23, %fd571;
	sub.f64 	%fd36, %fd22, %fd305;
	ld.global.f64 	%fd37, [%rd26];
	mov.f64 	%fd573, %fd185;
	@%p8 bra 	BB0_29;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r148, %temp}, %fd185;
	}
	setp.ne.s32	%p19, %r148, 0;
	mov.f64 	%fd573, %fd185;
	@%p19 bra 	BB0_29;

	mov.f64 	%fd306, 0d0000000000000000;
	mul.rn.f64 	%fd573, %fd185, %fd306;

BB0_29:
	mul.f64 	%fd307, %fd573, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64	%r339, %fd307;
	st.local.u32 	[%rd50], %r339;
	cvt.rn.f64.s32	%fd308, %r339;
	neg.f64 	%fd309, %fd308;
	fma.rn.f64 	%fd311, %fd309, %fd252, %fd573;
	fma.rn.f64 	%fd313, %fd309, %fd263, %fd311;
	fma.rn.f64 	%fd574, %fd309, %fd265, %fd313;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r149}, %fd573;
	}
	and.b32  	%r150, %r149, 2145386496;
	setp.lt.u32	%p20, %r150, 1105199104;
	@%p20 bra 	BB0_31;

	// Callseq Start 2
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd573;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd49;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd574, [retval0+0];
	
	//{
	}// Callseq End 2
	ld.local.u32 	%r339, [%rd50];

BB0_31:
	and.b32  	%r151, %r339, 1;
	shl.b32 	%r152, %r151, 3;
	setp.eq.s32	%p21, %r151, 0;
	selp.f64	%fd315, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p21;
	add.s32 	%r153, %r152, 1;
	mul.wide.s32 	%rd73, %r153, 8;
	add.s64 	%rd75, %rd54, %rd73;
	ld.const.f64 	%fd316, [%rd75];
	mul.rn.f64 	%fd43, %fd574, %fd574;
	fma.rn.f64 	%fd317, %fd315, %fd43, %fd316;
	ld.const.f64 	%fd318, [%rd75+8];
	fma.rn.f64 	%fd319, %fd317, %fd43, %fd318;
	ld.const.f64 	%fd320, [%rd75+16];
	fma.rn.f64 	%fd321, %fd319, %fd43, %fd320;
	ld.const.f64 	%fd322, [%rd75+24];
	fma.rn.f64 	%fd323, %fd321, %fd43, %fd322;
	ld.const.f64 	%fd324, [%rd75+32];
	fma.rn.f64 	%fd325, %fd323, %fd43, %fd324;
	ld.const.f64 	%fd326, [%rd75+40];
	fma.rn.f64 	%fd44, %fd325, %fd43, %fd326;
	fma.rn.f64 	%fd575, %fd44, %fd574, %fd574;
	@%p21 bra 	BB0_33;

	mov.f64 	%fd327, 0d3FF0000000000000;
	fma.rn.f64 	%fd575, %fd44, %fd43, %fd327;

BB0_33:
	and.b32  	%r154, %r339, 2;
	setp.eq.s32	%p22, %r154, 0;
	@%p22 bra 	BB0_35;

	mov.f64 	%fd328, 0d0000000000000000;
	mov.f64 	%fd329, 0dBFF0000000000000;
	fma.rn.f64 	%fd575, %fd575, %fd329, %fd328;

BB0_35:
	mul.f64 	%fd50, %fd37, %fd575;
	ld.global.f64 	%fd51, [%rd30];
	mov.f64 	%fd577, %fd185;
	@%p8 bra 	BB0_38;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r165, %temp}, %fd185;
	}
	setp.ne.s32	%p24, %r165, 0;
	mov.f64 	%fd577, %fd185;
	@%p24 bra 	BB0_38;

	mov.f64 	%fd330, 0d0000000000000000;
	mul.rn.f64 	%fd577, %fd185, %fd330;

BB0_38:
	mul.f64 	%fd331, %fd577, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64	%r340, %fd331;
	st.local.u32 	[%rd50], %r340;
	cvt.rn.f64.s32	%fd332, %r340;
	neg.f64 	%fd333, %fd332;
	fma.rn.f64 	%fd335, %fd333, %fd252, %fd577;
	fma.rn.f64 	%fd337, %fd333, %fd263, %fd335;
	fma.rn.f64 	%fd578, %fd333, %fd265, %fd337;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r166}, %fd577;
	}
	and.b32  	%r167, %r166, 2145386496;
	setp.lt.u32	%p25, %r167, 1105199104;
	@%p25 bra 	BB0_40;

	// Callseq Start 3
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd577;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd49;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd578, [retval0+0];
	
	//{
	}// Callseq End 3
	ld.local.u32 	%r340, [%rd50];

BB0_40:
	add.s32 	%r15, %r340, 1;
	and.b32  	%r168, %r15, 1;
	shl.b32 	%r169, %r168, 3;
	setp.eq.s32	%p26, %r168, 0;
	selp.f64	%fd339, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p26;
	add.s32 	%r170, %r169, 1;
	mul.wide.s32 	%rd83, %r170, 8;
	add.s64 	%rd85, %rd54, %rd83;
	ld.const.f64 	%fd340, [%rd85];
	mul.rn.f64 	%fd57, %fd578, %fd578;
	fma.rn.f64 	%fd341, %fd339, %fd57, %fd340;
	ld.const.f64 	%fd342, [%rd85+8];
	fma.rn.f64 	%fd343, %fd341, %fd57, %fd342;
	ld.const.f64 	%fd344, [%rd85+16];
	fma.rn.f64 	%fd345, %fd343, %fd57, %fd344;
	ld.const.f64 	%fd346, [%rd85+24];
	fma.rn.f64 	%fd347, %fd345, %fd57, %fd346;
	ld.const.f64 	%fd348, [%rd85+32];
	fma.rn.f64 	%fd349, %fd347, %fd57, %fd348;
	ld.const.f64 	%fd350, [%rd85+40];
	fma.rn.f64 	%fd58, %fd349, %fd57, %fd350;
	fma.rn.f64 	%fd579, %fd58, %fd578, %fd578;
	@%p26 bra 	BB0_42;

	mov.f64 	%fd351, 0d3FF0000000000000;
	fma.rn.f64 	%fd579, %fd58, %fd57, %fd351;

BB0_42:
	and.b32  	%r171, %r15, 2;
	setp.eq.s32	%p27, %r171, 0;
	@%p27 bra 	BB0_44;

	mov.f64 	%fd352, 0d0000000000000000;
	mov.f64 	%fd353, 0dBFF0000000000000;
	fma.rn.f64 	%fd579, %fd579, %fd353, %fd352;

BB0_44:
	fma.rn.f64 	%fd354, %fd51, %fd579, %fd50;
	st.global.f64 	[%rd30], %fd354;
	st.global.f64 	[%rd26], %fd36;
	ld.global.f64 	%fd599, [%rd1];
	setp.lt.f64	%p28, %fd599, 0d0000000000000000;
	@%p28 bra 	BB0_8;

BB0_45:
	setp.leu.f64	%p29, %fd599, %fd185;
	@%p29 bra 	BB0_84;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r182}, %fd185;
	}
	and.b32  	%r16, %r182, 2147483647;
	add.u64 	%rd93, %SP, 0;
	add.u64 	%rd2, %SPL, 0;

BB0_47:
	sub.f64 	%fd355, %fd599, %fd185;
	st.global.f64 	[%rd1], %fd355;
	ld.global.f64 	%fd67, [%rd26];
	setp.ne.s32	%p30, %r16, 2146435072;
	mov.f64 	%fd583, %fd185;
	@%p30 bra 	BB0_50;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r193, %temp}, %fd185;
	}
	setp.ne.s32	%p31, %r193, 0;
	mov.f64 	%fd583, %fd185;
	@%p31 bra 	BB0_50;

	mov.f64 	%fd356, 0d0000000000000000;
	mul.rn.f64 	%fd583, %fd185, %fd356;

BB0_50:
	mul.f64 	%fd357, %fd583, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64	%r341, %fd357;
	st.local.u32 	[%rd2], %r341;
	cvt.rn.f64.s32	%fd358, %r341;
	neg.f64 	%fd359, %fd358;
	fma.rn.f64 	%fd361, %fd359, %fd252, %fd583;
	mov.f64 	%fd362, 0d3C91A62633145C00;
	fma.rn.f64 	%fd363, %fd359, %fd362, %fd361;
	mov.f64 	%fd364, 0d397B839A252049C0;
	fma.rn.f64 	%fd584, %fd359, %fd364, %fd363;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r194}, %fd583;
	}
	and.b32  	%r195, %r194, 2145386496;
	setp.lt.u32	%p32, %r195, 1105199104;
	@%p32 bra 	BB0_52;

	// Callseq Start 4
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd583;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd93;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd584, [retval0+0];
	
	//{
	}// Callseq End 4
	ld.local.u32 	%r341, [%rd2];

BB0_52:
	add.s32 	%r20, %r341, 1;
	and.b32  	%r196, %r20, 1;
	shl.b32 	%r197, %r196, 3;
	setp.eq.s32	%p33, %r196, 0;
	selp.f64	%fd365, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p33;
	add.s32 	%r198, %r197, 1;
	mul.wide.s32 	%rd103, %r198, 8;
	mov.u64 	%rd104, __cudart_sin_cos_coeffs;
	add.s64 	%rd105, %rd104, %rd103;
	ld.const.f64 	%fd366, [%rd105];
	mul.rn.f64 	%fd73, %fd584, %fd584;
	fma.rn.f64 	%fd367, %fd365, %fd73, %fd366;
	ld.const.f64 	%fd368, [%rd105+8];
	fma.rn.f64 	%fd369, %fd367, %fd73, %fd368;
	ld.const.f64 	%fd370, [%rd105+16];
	fma.rn.f64 	%fd371, %fd369, %fd73, %fd370;
	ld.const.f64 	%fd372, [%rd105+24];
	fma.rn.f64 	%fd373, %fd371, %fd73, %fd372;
	ld.const.f64 	%fd374, [%rd105+32];
	fma.rn.f64 	%fd375, %fd373, %fd73, %fd374;
	ld.const.f64 	%fd376, [%rd105+40];
	fma.rn.f64 	%fd74, %fd375, %fd73, %fd376;
	fma.rn.f64 	%fd585, %fd74, %fd584, %fd584;
	@%p33 bra 	BB0_54;

	mov.f64 	%fd377, 0d3FF0000000000000;
	fma.rn.f64 	%fd585, %fd74, %fd73, %fd377;

BB0_54:
	and.b32  	%r199, %r20, 2;
	setp.eq.s32	%p34, %r199, 0;
	@%p34 bra 	BB0_56;

	mov.f64 	%fd378, 0d0000000000000000;
	mov.f64 	%fd379, 0dBFF0000000000000;
	fma.rn.f64 	%fd585, %fd585, %fd379, %fd378;

BB0_56:
	mul.f64 	%fd80, %fd67, %fd585;
	ld.global.f64 	%fd81, [%rd30];
	mov.f64 	%fd587, %fd185;
	@%p30 bra 	BB0_59;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r200, %temp}, %fd185;
	}
	setp.ne.s32	%p36, %r200, 0;
	mov.f64 	%fd587, %fd185;
	@%p36 bra 	BB0_59;

	mov.f64 	%fd380, 0d0000000000000000;
	mul.rn.f64 	%fd587, %fd185, %fd380;

BB0_59:
	mul.f64 	%fd381, %fd587, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64	%r342, %fd381;
	st.local.u32 	[%rd2], %r342;
	cvt.rn.f64.s32	%fd382, %r342;
	neg.f64 	%fd383, %fd382;
	fma.rn.f64 	%fd385, %fd383, %fd252, %fd587;
	fma.rn.f64 	%fd387, %fd383, %fd362, %fd385;
	fma.rn.f64 	%fd588, %fd383, %fd364, %fd387;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r201}, %fd587;
	}
	and.b32  	%r202, %r201, 2145386496;
	setp.lt.u32	%p37, %r202, 1105199104;
	@%p37 bra 	BB0_61;

	// Callseq Start 5
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd587;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd93;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd588, [retval0+0];
	
	//{
	}// Callseq End 5
	ld.local.u32 	%r342, [%rd2];

BB0_61:
	and.b32  	%r203, %r342, 1;
	shl.b32 	%r204, %r203, 3;
	setp.eq.s32	%p38, %r203, 0;
	selp.f64	%fd389, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p38;
	add.s32 	%r205, %r204, 1;
	mul.wide.s32 	%rd108, %r205, 8;
	add.s64 	%rd110, %rd104, %rd108;
	ld.const.f64 	%fd390, [%rd110];
	mul.rn.f64 	%fd87, %fd588, %fd588;
	fma.rn.f64 	%fd391, %fd389, %fd87, %fd390;
	ld.const.f64 	%fd392, [%rd110+8];
	fma.rn.f64 	%fd393, %fd391, %fd87, %fd392;
	ld.const.f64 	%fd394, [%rd110+16];
	fma.rn.f64 	%fd395, %fd393, %fd87, %fd394;
	ld.const.f64 	%fd396, [%rd110+24];
	fma.rn.f64 	%fd397, %fd395, %fd87, %fd396;
	ld.const.f64 	%fd398, [%rd110+32];
	fma.rn.f64 	%fd399, %fd397, %fd87, %fd398;
	ld.const.f64 	%fd400, [%rd110+40];
	fma.rn.f64 	%fd88, %fd399, %fd87, %fd400;
	fma.rn.f64 	%fd589, %fd88, %fd588, %fd588;
	@%p38 bra 	BB0_63;

	mov.f64 	%fd401, 0d3FF0000000000000;
	fma.rn.f64 	%fd589, %fd88, %fd87, %fd401;

BB0_63:
	and.b32  	%r206, %r342, 2;
	setp.eq.s32	%p39, %r206, 0;
	@%p39 bra 	BB0_65;

	mov.f64 	%fd402, 0d0000000000000000;
	mov.f64 	%fd403, 0dBFF0000000000000;
	fma.rn.f64 	%fd589, %fd589, %fd403, %fd402;

BB0_65:
	fma.rn.f64 	%fd94, %fd81, %fd589, %fd80;
	ld.global.f64 	%fd95, [%rd26];
	mov.f64 	%fd591, %fd185;
	@%p30 bra 	BB0_68;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r207, %temp}, %fd185;
	}
	setp.ne.s32	%p41, %r207, 0;
	mov.f64 	%fd591, %fd185;
	@%p41 bra 	BB0_68;

	mov.f64 	%fd404, 0d0000000000000000;
	mul.rn.f64 	%fd591, %fd185, %fd404;

BB0_68:
	mul.f64 	%fd405, %fd591, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64	%r343, %fd405;
	st.local.u32 	[%rd2], %r343;
	cvt.rn.f64.s32	%fd406, %r343;
	neg.f64 	%fd407, %fd406;
	fma.rn.f64 	%fd409, %fd407, %fd252, %fd591;
	fma.rn.f64 	%fd411, %fd407, %fd362, %fd409;
	fma.rn.f64 	%fd592, %fd407, %fd364, %fd411;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r208}, %fd591;
	}
	and.b32  	%r209, %r208, 2145386496;
	setp.lt.u32	%p42, %r209, 1105199104;
	@%p42 bra 	BB0_70;

	// Callseq Start 6
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd591;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd93;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd592, [retval0+0];
	
	//{
	}// Callseq End 6
	ld.local.u32 	%r343, [%rd2];

BB0_70:
	and.b32  	%r210, %r343, 1;
	shl.b32 	%r211, %r210, 3;
	setp.eq.s32	%p43, %r210, 0;
	selp.f64	%fd413, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p43;
	add.s32 	%r212, %r211, 1;
	mul.wide.s32 	%rd113, %r212, 8;
	add.s64 	%rd115, %rd104, %rd113;
	ld.const.f64 	%fd414, [%rd115];
	mul.rn.f64 	%fd101, %fd592, %fd592;
	fma.rn.f64 	%fd415, %fd413, %fd101, %fd414;
	ld.const.f64 	%fd416, [%rd115+8];
	fma.rn.f64 	%fd417, %fd415, %fd101, %fd416;
	ld.const.f64 	%fd418, [%rd115+16];
	fma.rn.f64 	%fd419, %fd417, %fd101, %fd418;
	ld.const.f64 	%fd420, [%rd115+24];
	fma.rn.f64 	%fd421, %fd419, %fd101, %fd420;
	ld.const.f64 	%fd422, [%rd115+32];
	fma.rn.f64 	%fd423, %fd421, %fd101, %fd422;
	ld.const.f64 	%fd424, [%rd115+40];
	fma.rn.f64 	%fd102, %fd423, %fd101, %fd424;
	fma.rn.f64 	%fd593, %fd102, %fd592, %fd592;
	@%p43 bra 	BB0_72;

	mov.f64 	%fd425, 0d3FF0000000000000;
	fma.rn.f64 	%fd593, %fd102, %fd101, %fd425;

BB0_72:
	and.b32  	%r213, %r343, 2;
	setp.eq.s32	%p44, %r213, 0;
	@%p44 bra 	BB0_74;

	mov.f64 	%fd426, 0d0000000000000000;
	mov.f64 	%fd427, 0dBFF0000000000000;
	fma.rn.f64 	%fd593, %fd593, %fd427, %fd426;

BB0_74:
	mul.f64 	%fd108, %fd95, %fd593;
	ld.global.f64 	%fd109, [%rd30];
	mov.f64 	%fd595, %fd185;
	@%p30 bra 	BB0_77;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r214, %temp}, %fd185;
	}
	setp.ne.s32	%p46, %r214, 0;
	mov.f64 	%fd595, %fd185;
	@%p46 bra 	BB0_77;

	mov.f64 	%fd428, 0d0000000000000000;
	mul.rn.f64 	%fd595, %fd185, %fd428;

BB0_77:
	mul.f64 	%fd429, %fd595, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64	%r344, %fd429;
	st.local.u32 	[%rd2], %r344;
	cvt.rn.f64.s32	%fd430, %r344;
	neg.f64 	%fd431, %fd430;
	fma.rn.f64 	%fd433, %fd431, %fd252, %fd595;
	fma.rn.f64 	%fd435, %fd431, %fd362, %fd433;
	fma.rn.f64 	%fd596, %fd431, %fd364, %fd435;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r215}, %fd595;
	}
	and.b32  	%r216, %r215, 2145386496;
	setp.lt.u32	%p47, %r216, 1105199104;
	@%p47 bra 	BB0_79;

	// Callseq Start 7
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd595;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd93;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd596, [retval0+0];
	
	//{
	}// Callseq End 7
	ld.local.u32 	%r344, [%rd2];

BB0_79:
	add.s32 	%r30, %r344, 1;
	and.b32  	%r217, %r30, 1;
	shl.b32 	%r218, %r217, 3;
	setp.eq.s32	%p48, %r217, 0;
	selp.f64	%fd437, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p48;
	add.s32 	%r219, %r218, 1;
	mul.wide.s32 	%rd118, %r219, 8;
	add.s64 	%rd120, %rd104, %rd118;
	ld.const.f64 	%fd438, [%rd120];
	mul.rn.f64 	%fd115, %fd596, %fd596;
	fma.rn.f64 	%fd439, %fd437, %fd115, %fd438;
	ld.const.f64 	%fd440, [%rd120+8];
	fma.rn.f64 	%fd441, %fd439, %fd115, %fd440;
	ld.const.f64 	%fd442, [%rd120+16];
	fma.rn.f64 	%fd443, %fd441, %fd115, %fd442;
	ld.const.f64 	%fd444, [%rd120+24];
	fma.rn.f64 	%fd445, %fd443, %fd115, %fd444;
	ld.const.f64 	%fd446, [%rd120+32];
	fma.rn.f64 	%fd447, %fd445, %fd115, %fd446;
	ld.const.f64 	%fd448, [%rd120+40];
	fma.rn.f64 	%fd116, %fd447, %fd115, %fd448;
	fma.rn.f64 	%fd597, %fd116, %fd596, %fd596;
	@%p48 bra 	BB0_81;

	mov.f64 	%fd449, 0d3FF0000000000000;
	fma.rn.f64 	%fd597, %fd116, %fd115, %fd449;

BB0_81:
	and.b32  	%r220, %r30, 2;
	setp.eq.s32	%p49, %r220, 0;
	@%p49 bra 	BB0_83;

	mov.f64 	%fd450, 0d0000000000000000;
	mov.f64 	%fd451, 0dBFF0000000000000;
	fma.rn.f64 	%fd597, %fd597, %fd451, %fd450;

BB0_83:
	mul.f64 	%fd452, %fd109, %fd597;
	sub.f64 	%fd453, %fd452, %fd108;
	st.global.f64 	[%rd30], %fd453;
	st.global.f64 	[%rd26], %fd94;
	ld.global.f64 	%fd599, [%rd1];
	setp.gt.f64	%p50, %fd599, %fd185;
	@%p50 bra 	BB0_47;

BB0_84:
	ld.global.f64 	%fd124, [%rd36];
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r231}, %fd599;
	}
	and.b32  	%r232, %r231, 2147483647;
	setp.ne.s32	%p51, %r232, 2146435072;
	@%p51 bra 	BB0_87;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r233, %temp}, %fd599;
	}
	setp.ne.s32	%p52, %r233, 0;
	@%p52 bra 	BB0_87;

	mov.f64 	%fd454, 0d0000000000000000;
	mul.rn.f64 	%fd599, %fd599, %fd454;

BB0_87:
	mul.f64 	%fd455, %fd599, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64	%r345, %fd455;
	add.u64 	%rd124, %SP, 0;
	add.u64 	%rd125, %SPL, 0;
	st.local.u32 	[%rd125], %r345;
	cvt.rn.f64.s32	%fd456, %r345;
	neg.f64 	%fd457, %fd456;
	fma.rn.f64 	%fd459, %fd457, %fd252, %fd599;
	mov.f64 	%fd460, 0d3C91A62633145C00;
	fma.rn.f64 	%fd461, %fd457, %fd460, %fd459;
	mov.f64 	%fd462, 0d397B839A252049C0;
	fma.rn.f64 	%fd601, %fd457, %fd462, %fd461;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r234}, %fd599;
	}
	and.b32  	%r235, %r234, 2145386496;
	setp.lt.u32	%p53, %r235, 1105199104;
	@%p53 bra 	BB0_89;

	// Callseq Start 8
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd599;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd124;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd601, [retval0+0];
	
	//{
	}// Callseq End 8
	ld.local.u32 	%r345, [%rd125];

BB0_89:
	add.s32 	%r34, %r345, 1;
	and.b32  	%r236, %r34, 1;
	shl.b32 	%r237, %r236, 3;
	setp.eq.s32	%p54, %r236, 0;
	selp.f64	%fd463, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p54;
	add.s32 	%r238, %r237, 1;
	mul.wide.s32 	%rd128, %r238, 8;
	mov.u64 	%rd129, __cudart_sin_cos_coeffs;
	add.s64 	%rd130, %rd129, %rd128;
	ld.const.f64 	%fd464, [%rd130];
	mul.rn.f64 	%fd130, %fd601, %fd601;
	fma.rn.f64 	%fd465, %fd463, %fd130, %fd464;
	ld.const.f64 	%fd466, [%rd130+8];
	fma.rn.f64 	%fd467, %fd465, %fd130, %fd466;
	ld.const.f64 	%fd468, [%rd130+16];
	fma.rn.f64 	%fd469, %fd467, %fd130, %fd468;
	ld.const.f64 	%fd470, [%rd130+24];
	fma.rn.f64 	%fd471, %fd469, %fd130, %fd470;
	ld.const.f64 	%fd472, [%rd130+32];
	fma.rn.f64 	%fd473, %fd471, %fd130, %fd472;
	ld.const.f64 	%fd474, [%rd130+40];
	fma.rn.f64 	%fd131, %fd473, %fd130, %fd474;
	fma.rn.f64 	%fd602, %fd131, %fd601, %fd601;
	@%p54 bra 	BB0_91;

	mov.f64 	%fd475, 0d3FF0000000000000;
	fma.rn.f64 	%fd602, %fd131, %fd130, %fd475;

BB0_91:
	and.b32  	%r239, %r34, 2;
	setp.eq.s32	%p55, %r239, 0;
	@%p55 bra 	BB0_93;

	mov.f64 	%fd476, 0d0000000000000000;
	mov.f64 	%fd477, 0dBFF0000000000000;
	fma.rn.f64 	%fd602, %fd602, %fd477, %fd476;

BB0_93:
	ld.param.u64 	%rd189, [_Z24processMandelbrotElementPdS_S_S_S_S_S_S_S_Piidddddd_param_0];
	cvta.to.global.u64 	%rd188, %rd189;
	add.s64 	%rd187, %rd188, %rd23;
	mul.f64 	%fd478, %fd124, %fd602;
	st.global.f64 	[%rd187], %fd478;
	ld.global.f64 	%fd137, [%rd36];
	ld.global.f64 	%fd604, [%rd1];
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r250}, %fd604;
	}
	and.b32  	%r251, %r250, 2147483647;
	setp.ne.s32	%p56, %r251, 2146435072;
	@%p56 bra 	BB0_96;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r252, %temp}, %fd604;
	}
	setp.ne.s32	%p57, %r252, 0;
	@%p57 bra 	BB0_96;

	mov.f64 	%fd479, 0d0000000000000000;
	mul.rn.f64 	%fd604, %fd604, %fd479;

BB0_96:
	mul.f64 	%fd480, %fd604, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64	%r346, %fd480;
	st.local.u32 	[%rd125], %r346;
	cvt.rn.f64.s32	%fd481, %r346;
	neg.f64 	%fd482, %fd481;
	fma.rn.f64 	%fd484, %fd482, %fd252, %fd604;
	fma.rn.f64 	%fd486, %fd482, %fd460, %fd484;
	fma.rn.f64 	%fd605, %fd482, %fd462, %fd486;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r253}, %fd604;
	}
	and.b32  	%r254, %r253, 2145386496;
	setp.lt.u32	%p58, %r254, 1105199104;
	@%p58 bra 	BB0_98;

	// Callseq Start 9
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd604;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd124;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd605, [retval0+0];
	
	//{
	}// Callseq End 9
	ld.local.u32 	%r346, [%rd125];

BB0_98:
	and.b32  	%r255, %r346, 1;
	shl.b32 	%r256, %r255, 3;
	setp.eq.s32	%p59, %r255, 0;
	selp.f64	%fd488, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p59;
	add.s32 	%r257, %r256, 1;
	mul.wide.s32 	%rd142, %r257, 8;
	add.s64 	%rd144, %rd129, %rd142;
	ld.const.f64 	%fd489, [%rd144];
	mul.rn.f64 	%fd144, %fd605, %fd605;
	fma.rn.f64 	%fd490, %fd488, %fd144, %fd489;
	ld.const.f64 	%fd491, [%rd144+8];
	fma.rn.f64 	%fd492, %fd490, %fd144, %fd491;
	ld.const.f64 	%fd493, [%rd144+16];
	fma.rn.f64 	%fd494, %fd492, %fd144, %fd493;
	ld.const.f64 	%fd495, [%rd144+24];
	fma.rn.f64 	%fd496, %fd494, %fd144, %fd495;
	ld.const.f64 	%fd497, [%rd144+32];
	fma.rn.f64 	%fd498, %fd496, %fd144, %fd497;
	ld.const.f64 	%fd499, [%rd144+40];
	fma.rn.f64 	%fd145, %fd498, %fd144, %fd499;
	fma.rn.f64 	%fd606, %fd145, %fd605, %fd605;
	@%p59 bra 	BB0_100;

	mov.f64 	%fd500, 0d3FF0000000000000;
	fma.rn.f64 	%fd606, %fd145, %fd144, %fd500;

BB0_100:
	and.b32  	%r258, %r346, 2;
	setp.eq.s32	%p60, %r258, 0;
	@%p60 bra 	BB0_102;

	mov.f64 	%fd501, 0d0000000000000000;
	mov.f64 	%fd502, 0dBFF0000000000000;
	fma.rn.f64 	%fd606, %fd606, %fd502, %fd501;

BB0_102:
	ld.param.f64 	%fd560, [_Z24processMandelbrotElementPdS_S_S_S_S_S_S_S_Piidddddd_param_12];
	ld.param.u64 	%rd192, [_Z24processMandelbrotElementPdS_S_S_S_S_S_S_S_Piidddddd_param_1];
	cvta.to.global.u64 	%rd191, %rd192;
	add.s64 	%rd190, %rd191, %rd23;
	mul.f64 	%fd503, %fd137, %fd606;
	st.global.f64 	[%rd190], %fd503;
	ld.global.f64 	%fd608, [%rd32];
	setp.leu.f64	%p61, %fd608, %fd560;
	@%p61 bra 	BB0_104;

	ld.param.u64 	%rd199, [_Z24processMandelbrotElementPdS_S_S_S_S_S_S_S_Piidddddd_param_5];
	cvta.to.global.u64 	%rd198, %rd199;
	add.s64 	%rd197, %rd198, %rd23;
	ld.param.f64 	%fd561, [_Z24processMandelbrotElementPdS_S_S_S_S_S_S_S_Piidddddd_param_12];
	add.f64 	%fd504, %fd561, %fd561;
	sub.f64 	%fd505, %fd504, %fd608;
	st.global.f64 	[%rd32], %fd505;
	ld.global.f64 	%fd506, [%rd197];
	neg.f64 	%fd507, %fd506;
	st.global.f64 	[%rd197], %fd507;
	ld.global.f64 	%fd608, [%rd32];

BB0_104:
	setp.geu.f64	%p62, %fd608, 0d0000000000000000;
	@%p62 bra 	BB0_106;

	ld.param.u64 	%rd196, [_Z24processMandelbrotElementPdS_S_S_S_S_S_S_S_Piidddddd_param_5];
	cvta.to.global.u64 	%rd195, %rd196;
	add.s64 	%rd194, %rd195, %rd23;
	neg.f64 	%fd508, %fd608;
	st.global.f64 	[%rd32], %fd508;
	ld.global.f64 	%fd509, [%rd194];
	neg.f64 	%fd510, %fd509;
	st.global.f64 	[%rd194], %fd510;

BB0_106:
	ld.global.f64 	%fd154, [%rd26];
	ld.global.f64 	%fd609, [%rd1];
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r299}, %fd609;
	}
	and.b32  	%r300, %r299, 2147483647;
	setp.ne.s32	%p63, %r300, 2146435072;
	@%p63 bra 	BB0_109;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r301, %temp}, %fd609;
	}
	setp.ne.s32	%p64, %r301, 0;
	@%p64 bra 	BB0_109;

	mov.f64 	%fd511, 0d0000000000000000;
	mul.rn.f64 	%fd609, %fd609, %fd511;

BB0_109:
	mul.f64 	%fd512, %fd609, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64	%r347, %fd512;
	st.local.u32 	[%rd125], %r347;
	cvt.rn.f64.s32	%fd513, %r347;
	neg.f64 	%fd514, %fd513;
	fma.rn.f64 	%fd516, %fd514, %fd252, %fd609;
	fma.rn.f64 	%fd518, %fd514, %fd460, %fd516;
	fma.rn.f64 	%fd610, %fd514, %fd462, %fd518;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r302}, %fd609;
	}
	and.b32  	%r303, %r302, 2145386496;
	setp.lt.u32	%p65, %r303, 1105199104;
	@%p65 bra 	BB0_111;

	// Callseq Start 10
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd609;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd124;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd610, [retval0+0];
	
	//{
	}// Callseq End 10
	ld.local.u32 	%r347, [%rd125];

BB0_111:
	add.s32 	%r41, %r347, 1;
	and.b32  	%r304, %r41, 1;
	shl.b32 	%r305, %r304, 3;
	setp.eq.s32	%p66, %r304, 0;
	selp.f64	%fd520, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p66;
	add.s32 	%r306, %r305, 1;
	mul.wide.s32 	%rd169, %r306, 8;
	add.s64 	%rd171, %rd129, %rd169;
	ld.const.f64 	%fd521, [%rd171];
	mul.rn.f64 	%fd161, %fd610, %fd610;
	fma.rn.f64 	%fd522, %fd520, %fd161, %fd521;
	ld.const.f64 	%fd523, [%rd171+8];
	fma.rn.f64 	%fd524, %fd522, %fd161, %fd523;
	ld.const.f64 	%fd525, [%rd171+16];
	fma.rn.f64 	%fd526, %fd524, %fd161, %fd525;
	ld.const.f64 	%fd527, [%rd171+24];
	fma.rn.f64 	%fd528, %fd526, %fd161, %fd527;
	ld.const.f64 	%fd529, [%rd171+32];
	fma.rn.f64 	%fd530, %fd528, %fd161, %fd529;
	ld.const.f64 	%fd531, [%rd171+40];
	fma.rn.f64 	%fd162, %fd530, %fd161, %fd531;
	fma.rn.f64 	%fd611, %fd162, %fd610, %fd610;
	@%p66 bra 	BB0_113;

	mov.f64 	%fd532, 0d3FF0000000000000;
	fma.rn.f64 	%fd611, %fd162, %fd161, %fd532;

BB0_113:
	and.b32  	%r307, %r41, 2;
	setp.eq.s32	%p67, %r307, 0;
	@%p67 bra 	BB0_115;

	mov.f64 	%fd533, 0d0000000000000000;
	mov.f64 	%fd534, 0dBFF0000000000000;
	fma.rn.f64 	%fd611, %fd611, %fd534, %fd533;

BB0_115:
	mul.f64 	%fd168, %fd154, %fd611;
	ld.global.f64 	%fd169, [%rd30];
	ld.global.f64 	%fd613, [%rd1];
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r318}, %fd613;
	}
	and.b32  	%r319, %r318, 2147483647;
	setp.ne.s32	%p68, %r319, 2146435072;
	@%p68 bra 	BB0_118;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r320, %temp}, %fd613;
	}
	setp.ne.s32	%p69, %r320, 0;
	@%p69 bra 	BB0_118;

	mov.f64 	%fd535, 0d0000000000000000;
	mul.rn.f64 	%fd613, %fd613, %fd535;

BB0_118:
	mul.f64 	%fd536, %fd613, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64	%r348, %fd536;
	st.local.u32 	[%rd125], %r348;
	cvt.rn.f64.s32	%fd537, %r348;
	neg.f64 	%fd538, %fd537;
	fma.rn.f64 	%fd540, %fd538, %fd252, %fd613;
	fma.rn.f64 	%fd542, %fd538, %fd460, %fd540;
	fma.rn.f64 	%fd614, %fd538, %fd462, %fd542;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r321}, %fd613;
	}
	and.b32  	%r322, %r321, 2145386496;
	setp.lt.u32	%p70, %r322, 1105199104;
	@%p70 bra 	BB0_120;

	// Callseq Start 11
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd613;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd124;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd614, [retval0+0];
	
	//{
	}// Callseq End 11
	ld.local.u32 	%r348, [%rd125];

BB0_120:
	and.b32  	%r323, %r348, 1;
	shl.b32 	%r324, %r323, 3;
	setp.eq.s32	%p71, %r323, 0;
	selp.f64	%fd544, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p71;
	add.s32 	%r325, %r324, 1;
	mul.wide.s32 	%rd181, %r325, 8;
	add.s64 	%rd183, %rd129, %rd181;
	ld.const.f64 	%fd545, [%rd183];
	mul.rn.f64 	%fd176, %fd614, %fd614;
	fma.rn.f64 	%fd546, %fd544, %fd176, %fd545;
	ld.const.f64 	%fd547, [%rd183+8];
	fma.rn.f64 	%fd548, %fd546, %fd176, %fd547;
	ld.const.f64 	%fd549, [%rd183+16];
	fma.rn.f64 	%fd550, %fd548, %fd176, %fd549;
	ld.const.f64 	%fd551, [%rd183+24];
	fma.rn.f64 	%fd552, %fd550, %fd176, %fd551;
	ld.const.f64 	%fd553, [%rd183+32];
	fma.rn.f64 	%fd554, %fd552, %fd176, %fd553;
	ld.const.f64 	%fd555, [%rd183+40];
	fma.rn.f64 	%fd177, %fd554, %fd176, %fd555;
	fma.rn.f64 	%fd615, %fd177, %fd614, %fd614;
	@%p71 bra 	BB0_122;

	mov.f64 	%fd556, 0d3FF0000000000000;
	fma.rn.f64 	%fd615, %fd177, %fd176, %fd556;

BB0_122:
	and.b32  	%r326, %r348, 2;
	setp.eq.s32	%p72, %r326, 0;
	@%p72 bra 	BB0_124;

	mov.f64 	%fd557, 0d0000000000000000;
	mov.f64 	%fd558, 0dBFF0000000000000;
	fma.rn.f64 	%fd615, %fd615, %fd558, %fd557;

BB0_124:
	ld.param.u64 	%rd193, [_Z24processMandelbrotElementPdS_S_S_S_S_S_S_S_Piidddddd_param_8];
	fma.rn.f64 	%fd559, %fd169, %fd615, %fd168;
	cvta.to.global.u64 	%rd184, %rd193;
	add.s64 	%rd186, %rd184, %rd23;
	st.global.f64 	[%rd186], %fd559;

BB0_125:
	ret;
}

.func  (.param .b64 func_retval0) __internal_trig_reduction_slowpathd(
	.param .b64 __internal_trig_reduction_slowpathd_param_0,
	.param .b64 __internal_trig_reduction_slowpathd_param_1
)
{
	.local .align 8 .b8 	__local_depot1[40];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<9>;
	.reg .b32 	%r<42>;
	.reg .f64 	%fd<5>;
	.reg .b64 	%rd<101>;


	mov.u64 	%SPL, __local_depot1;
	ld.param.f64 	%fd4, [__internal_trig_reduction_slowpathd_param_0];
	ld.param.u64 	%rd37, [__internal_trig_reduction_slowpathd_param_1];
	add.u64 	%rd1, %SPL, 0;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1}, %fd4;
	}
	and.b32  	%r40, %r1, -2147483648;
	shr.u32 	%r3, %r1, 20;
	bfe.u32 	%r4, %r1, 20, 11;
	setp.eq.s32	%p1, %r4, 2047;
	@%p1 bra 	BB1_13;

	add.s32 	%r15, %r4, -1024;
	shr.u32 	%r16, %r15, 6;
	mov.u32 	%r17, 15;
	sub.s32 	%r5, %r17, %r16;
	mov.u32 	%r18, 19;
	sub.s32 	%r19, %r18, %r16;
	mov.u32 	%r20, 18;
	min.s32 	%r6, %r20, %r19;
	mov.u64 	%rd94, 0;
	setp.ge.s32	%p2, %r5, %r6;
	mov.u64 	%rd93, %rd1;
	@%p2 bra 	BB1_4;

	bfe.u32 	%r21, %r1, 20, 11;
	add.s32 	%r22, %r21, -1024;
	shr.u32 	%r23, %r22, 6;
	sub.s32 	%r25, %r17, %r23;
	mul.wide.s32 	%rd41, %r25, 8;
	mov.u64 	%rd42, __cudart_i2opi_d;
	add.s64 	%rd89, %rd42, %rd41;
	mov.b64 	 %rd43, %fd4;
	shl.b64 	%rd44, %rd43, 11;
	or.b64  	%rd5, %rd44, -9223372036854775808;
	mov.u64 	%rd94, 0;
	mov.u64 	%rd93, %rd1;
	mov.u64 	%rd91, %rd1;
	mov.u32 	%r39, %r5;

BB1_3:
	.pragma "nounroll";
	ld.const.u64 	%rd47, [%rd89];
	// inline asm
	{
	.reg .u32 r0, r1, r2, r3, alo, ahi, blo, bhi, clo, chi;
	mov.b64         {alo,ahi}, %rd47;    
	mov.b64         {blo,bhi}, %rd5;    
	mov.b64         {clo,chi}, %rd94;    
	mad.lo.cc.u32   r0, alo, blo, clo;
	madc.hi.cc.u32  r1, alo, blo, chi;
	madc.hi.u32     r2, alo, bhi,   0;
	mad.lo.cc.u32   r1, alo, bhi,  r1;
	madc.hi.cc.u32  r2, ahi, blo,  r2;
	madc.hi.u32     r3, ahi, bhi,   0;
	mad.lo.cc.u32   r1, ahi, blo,  r1;
	madc.lo.cc.u32  r2, ahi, bhi,  r2;
	addc.u32        r3,  r3,   0;     
	mov.b64         %rd45, {r0,r1};      
	mov.b64         %rd94, {r2,r3};      
	}
	// inline asm
	st.local.u64 	[%rd91], %rd45;
	add.s32 	%r39, %r39, 1;
	sub.s32 	%r26, %r39, %r5;
	mul.wide.s32 	%rd50, %r26, 8;
	add.s64 	%rd91, %rd1, %rd50;
	add.s64 	%rd93, %rd93, 8;
	add.s64 	%rd89, %rd89, 8;
	setp.lt.s32	%p3, %r39, %r6;
	@%p3 bra 	BB1_3;

BB1_4:
	st.local.u64 	[%rd93], %rd94;
	ld.local.u64 	%rd95, [%rd1+16];
	ld.local.u64 	%rd96, [%rd1+24];
	and.b32  	%r9, %r3, 63;
	setp.eq.s32	%p4, %r9, 0;
	@%p4 bra 	BB1_6;

	mov.u32 	%r27, 64;
	sub.s32 	%r28, %r27, %r9;
	shl.b64 	%rd51, %rd96, %r9;
	shr.u64 	%rd52, %rd95, %r28;
	or.b64  	%rd96, %rd51, %rd52;
	shl.b64 	%rd53, %rd95, %r9;
	ld.local.u64 	%rd54, [%rd1+8];
	shr.u64 	%rd55, %rd54, %r28;
	or.b64  	%rd95, %rd55, %rd53;

BB1_6:
	shr.u64 	%rd56, %rd96, 62;
	cvt.u32.u64	%r29, %rd56;
	shr.u64 	%rd57, %rd95, 62;
	shl.b64 	%rd58, %rd96, 2;
	or.b64  	%rd98, %rd58, %rd57;
	shl.b64 	%rd97, %rd95, 2;
	shr.u64 	%rd59, %rd96, 61;
	cvt.u32.u64	%r30, %rd59;
	and.b32  	%r31, %r30, 1;
	add.s32 	%r32, %r31, %r29;
	neg.s32 	%r33, %r32;
	setp.eq.s32	%p5, %r40, 0;
	selp.b32	%r34, %r32, %r33, %p5;
	cvta.to.local.u64 	%rd60, %rd37;
	st.local.u32 	[%rd60], %r34;
	setp.eq.s32	%p6, %r31, 0;
	@%p6 bra 	BB1_8;

	mov.u64 	%rd64, 0;
	// inline asm
	{
	.reg .u32 r0, r1, r2, r3, a0, a1, a2, a3, b0, b1, b2, b3;
	mov.b64         {a0,a1}, %rd64;
	mov.b64         {a2,a3}, %rd64;
	mov.b64         {b0,b1}, %rd97;
	mov.b64         {b2,b3}, %rd98;
	sub.cc.u32      r0, a0, b0; 
	subc.cc.u32     r1, a1, b1; 
	subc.cc.u32     r2, a2, b2; 
	subc.u32        r3, a3, b3; 
	mov.b64         %rd97, {r0,r1};
	mov.b64         %rd98, {r2,r3};
	}
	// inline asm
	xor.b32  	%r40, %r40, -2147483648;

BB1_8:
	clz.b64 	%r41, %rd98;
	setp.eq.s32	%p7, %r41, 0;
	@%p7 bra 	BB1_10;

	shl.b64 	%rd67, %rd98, %r41;
	mov.u32 	%r35, 64;
	sub.s32 	%r36, %r35, %r41;
	shr.u64 	%rd68, %rd97, %r36;
	or.b64  	%rd98, %rd68, %rd67;

BB1_10:
	mov.u64 	%rd72, -3958705157555305931;
	// inline asm
	{
	.reg .u32 r0, r1, r2, r3, alo, ahi, blo, bhi;
	mov.b64         {alo,ahi}, %rd98;   
	mov.b64         {blo,bhi}, %rd72;   
	mul.lo.u32      r0, alo, blo;    
	mul.hi.u32      r1, alo, blo;    
	mad.lo.cc.u32   r1, alo, bhi, r1;
	madc.hi.u32     r2, alo, bhi,  0;
	mad.lo.cc.u32   r1, ahi, blo, r1;
	madc.hi.cc.u32  r2, ahi, blo, r2;
	madc.hi.u32     r3, ahi, bhi,  0;
	mad.lo.cc.u32   r2, ahi, bhi, r2;
	addc.u32        r3, r3,  0;      
	mov.b64         %rd69, {r0,r1};     
	mov.b64         %rd100, {r2,r3};     
	}
	// inline asm
	setp.lt.s64	%p8, %rd100, 1;
	@%p8 bra 	BB1_12;

	// inline asm
	{
	.reg .u32 r0, r1, r2, r3, a0, a1, a2, a3, b0, b1, b2, b3;
	mov.b64         {a0,a1}, %rd69;
	mov.b64         {a2,a3}, %rd100;
	mov.b64         {b0,b1}, %rd69;
	mov.b64         {b2,b3}, %rd100;
	add.cc.u32      r0, a0, b0; 
	addc.cc.u32     r1, a1, b1; 
	addc.cc.u32     r2, a2, b2; 
	addc.u32        r3, a3, b3; 
	mov.b64         %rd73, {r0,r1};
	mov.b64         %rd100, {r2,r3};
	}
	// inline asm
	add.s32 	%r41, %r41, 1;

BB1_12:
	cvt.u64.u32	%rd79, %r40;
	shl.b64 	%rd80, %rd79, 32;
	mov.u32 	%r37, 1022;
	sub.s32 	%r38, %r37, %r41;
	cvt.u64.u32	%rd81, %r38;
	shl.b64 	%rd82, %rd81, 52;
	add.s64 	%rd83, %rd100, 1;
	shr.u64 	%rd84, %rd83, 10;
	add.s64 	%rd85, %rd84, 1;
	shr.u64 	%rd86, %rd85, 1;
	add.s64 	%rd87, %rd86, %rd82;
	or.b64  	%rd88, %rd87, %rd80;
	mov.b64 	 %fd4, %rd88;

BB1_13:
	st.param.f64	[func_retval0+0], %fd4;
	ret;
}


